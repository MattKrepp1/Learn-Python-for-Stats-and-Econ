{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JLCat\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datlib.FRED import *\n",
    "from datlib.plots import *\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "\n",
    "#FRED.py\n",
    "#. . . \n",
    "def bil_to_mil(series):\n",
    "    return series* 10**3\n",
    "# . . .\n",
    "#fedProject.py\n",
    "# . . .\n",
    "data_codes  = {# Assets\n",
    "               \"Balance Sheet: Total Assets ($ Mil)\": \"WALCL\",\n",
    "               \"Balance Sheet Securities, Prem-Disc, Repos, and Loans ($ Mil)\": \"WSRLL\",\n",
    "               \"Balance Sheet: Securities Held Outright ($ Mil)\": \"WSHOSHO\",\n",
    "               ### breakdown of securities holdings ###\n",
    "               \"Balance Sheet: U.S. Treasuries Held Outright ($ Mil)\":\"WSHOTSL\",\n",
    "               \"Balance Sheet: Federal Agency Debt Securities ($ Mil)\" : \"WSHOFADSL\",\n",
    "               \"Balance Sheet: Mortgage-Backed Securities ($ Mil)\": \"WSHOMCB\",\n",
    "               # other forms of lending\n",
    "               \"Balance Sheet: Repos ($ Mil)\": \"WORAL\",\n",
    "               \"Balance Sheet: Central Bank Liquidity Swaps ($ Mil)\" : \"SWPT\",\n",
    "               \"Balance Sheet: Direct Lending ($ Mil)\" : \"WLCFLL\",\n",
    "               # unamortized value of securities held (due to changes in interest rates)\n",
    "               \"Balance Sheet: Unamortized Security Premiums ($ Mil)\": \"WUPSHO\",\n",
    "               # Liabilities\n",
    "               \"Balance Sheet: Total Liabilities ($ Mil)\" : \"WLTLECL\",\n",
    "               \"Balance Sheet: Federal Reserve Notes Outstanding ($ Mil)\" : \"WLFN\",\n",
    "               \"Balance Sheet: Reverse Repos ($ Mil)\": \"WLRRAL\",\n",
    "               ### Major share of deposits \n",
    "               \"Balance Sheet: Deposits from Dep. Institutions ($ Mil)\":\"WLODLL\",\n",
    "               \"Balance Sheet: U.S. Treasury General Account ($ Mil)\": \"WDTGAL\",\n",
    "               \"Balance Sheet: Other Deposits ($ Mil)\": \"WOTHLB\",\n",
    "               \"Balance Sheet: All Deposits ($ Mil)\": \"WLDLCL\",\n",
    "               # Capital\n",
    "               \"Balance Sheet: Total Capital\": \"WCTCL\",\n",
    "               # Interest Rates\n",
    "               \"Unemployment Rate\": \"UNRATE\",\n",
    "               \"Nominal GDP ($ Bil)\":\"GDP\",\n",
    "               \"Real GDP ($ Bil)\":\"GDPC1\",\n",
    "               \"GDP Deflator\":\"GDPDEF\",\n",
    "               \"CPI\":\"CPIAUCSL\",\n",
    "               \"Core PCE\":\"PCEPILFE\",\n",
    "               \"Private Investment\":\"GPDI\",\n",
    "               \"Base: Total ($ Mil)\": \"BOGMBASE\",\n",
    "               \"Base: Currency in Circulation ($ Bil)\": \"WCURCIR\",\n",
    "               \"1 Month Treasury Rate (%)\": \"DGS1MO\",\n",
    "               \"3 Month Treasury Rate (%)\": \"DGS3MO\",               \n",
    "               \"1 Year Treasury Rate (%)\": \"DGS1\",\n",
    "               \"2 Year Treasury Rate (%)\": \"DGS2\",\n",
    "               \"10 Year Treasury Rate (%)\": \"DGS10\",\n",
    "               \"30 Year Treasury Rate (%)\": \"DGS30\",               \n",
    "               \"Effective Federal Funds Rate (%)\": \"DFF\",\n",
    "               \"Federal Funds Target Rate (Pre-crisis)\":\"DFEDTAR\",\n",
    "               \"Federal Funds Upper Target\":\"DFEDTARU\",\n",
    "               \"Federal Funds Lower Target\":\"DFEDTARL\",\n",
    "               \"Interest on Reserves (%)\": \"IOER\",\n",
    "               \"VIX\": \"VIXCLS\",\n",
    "                \"5 Year Forward Rate\": \"T5YIFR\"\n",
    "               }\n",
    "inflation_target = .02\n",
    "unemployment_target = .04\n",
    "# Select start and end dates\n",
    "start = datetime.datetime(2001, 12, 1)\n",
    "end = datetime.datetime.today()\n",
    "annual_div = {\"Q\":4,\n",
    "             \"W\":52,\n",
    "             \"M\":12}\n",
    "# freq refers to data frequency. Choose \"D\", \"W\", \"M\", \"Q\", \"A\"\n",
    "# a number may also be place in front of a letter. \"2D\" indicates\n",
    "#       alternating days\n",
    "if \"data_gathered\" not in locals():\n",
    "    freq = \"M\"\n",
    "    year = annual_div[freq]\n",
    "    data = gather_data(data_codes, start, \n",
    "          end = end, freq = freq)\n",
    "    data.fillna(0, inplace=True)\n",
    "    for key in data.keys():\n",
    "        data[\"Log \" + key]= np.log(data[key])\n",
    "    # Create new variables\n",
    "    data_gathered = True\n",
    "\n",
    "ticker = \"^GSPC\"\n",
    "data[\"Base: Currency in Circulation ($ Mil)\"] = data[\"Base: Currency in Circulation ($ Bil)\"].mul(1000)\n",
    "data[\"Base: Currency not in Circulation ($ Mil)\"] = data[\"Base: Total ($ Mil)\"].sub(data[\"Base: Currency in Circulation ($ Mil)\"])\n",
    "data[\"Currency in Circulation Growth Rate (%)\"] = data[\"Base: Currency in Circulation ($ Mil)\"].pct_change(year) * 100\n",
    "data[\"% Currency not in Circulation\"] = data[\"Base: Currency not in Circulation ($ Mil)\"].div(data[\"Base: Total ($ Mil)\"]) * 100\n",
    "data[\"% Currency in Circulation\"] = data[\"Base: Currency in Circulation ($ Mil)\"].div(data[\"Base: Total ($ Mil)\"]) * 100\n",
    "data[\"Base: Total Growth Rate (%)\"] = data[\"Base: Total ($ Mil)\"]\n",
    "data[\"Change % Currency not in Circulation\"] = data[\"% Currency not in Circulation\"].diff(year)    \n",
    "data[\"Currency not in Circulation Growth Rate (%)\"] = data[\"Base: Currency not in Circulation ($ Mil)\"].pct_change(year) * 100    \n",
    "data[\"Inflation (CPI)\"] =  web.DataReader(\"CPIAUCSL\", \"fred\", start, end).resample(freq).mean().pct_change(year).mul(100).dropna()\n",
    "data[\"Inflation (PCE)\"] = web.DataReader(\"PCEPILFE\", \"fred\", start, end).resample(freq).mean().pct_change(year).mul(100).dropna()\n",
    "\n",
    "data[\"Effective Federal Funds Rate Diff (%)\"] = data[\"Effective Federal Funds Rate (%)\"].diff(year)\n",
    "data[\"1 Year Treasury Rate (%; diff)\"] = data[\"1 Year Treasury Rate (%)\"].diff(year)\n",
    "data[\"2 Year Treasury Rate (%; diff)\"] = data[\"2 Year Treasury Rate (%)\"].diff(year)\n",
    "data[\"10 Year Treasury Rate (%; diff)\"] = data[\"10 Year Treasury Rate (%)\"].diff(year)\n",
    "data[\"30 Year Treasury Rate (%; diff)\"] = data[\"30 Year Treasury Rate (%)\"].diff(year)\n",
    "data[\"Unemployment Rate Diff\"] = data[\"Unemployment Rate\"].diff(year)\n",
    "data[\"Nominal GDP ($ Mil)\"] = data[\"Nominal GDP ($ Bil)\"].mul(1000)\n",
    "data[\"Nominal GDP Growth Rate (%)\"] = data[\"Nominal GDP ($ Bil)\"].pct_change(year) * 100\n",
    "data[\"Real GDP ($ Mil)\"] = data[\"Real GDP ($ Bil)\"].mul(1000)\n",
    "data[\"Real GDP Growth Rate (%)\"] = data[\"Real GDP ($ Bil)\"].pct_change(year) * 100\n",
    "data[\"Inflation (GDPDEF)\"] = data[\"GDP Deflator\"].pct_change(year) * 100\n",
    "data[\"Real Currency in Circulation Growth Rate (%)\"] = data[\"Currency in Circulation Growth Rate (%)\"].sub(data[\"Inflation (GDPDEF)\"])\n",
    "data[\"Currency in Circulation Velocity\"] = data[\"Nominal GDP ($ Mil)\"].div(data[\"Base: Currency in Circulation ($ Mil)\"])\n",
    "data[\"Currency in Circulation % Change Velocity\"] = data[\"Currency in Circulation Velocity\"].pct_change(year)\n",
    "\n",
    "data[\"Inflation Loss\"]= data[\"Inflation (PCE)\"].sub(inflation_target)\n",
    "data[\"Unemployment Loss\"]= data[\"Unemployment Rate\"].sub(unemployment_target)\n",
    "data[\"Inflation Loss Sq\"]= data[\"Inflation (PCE)\"].sub(inflation_target).pow(2)\n",
    "data[\"Inflation Loss Sq\"][data[\"Inflation Loss\"] < 0] = data[\"Inflation Loss Sq\"].mul(-1)\n",
    "\n",
    "data[\"Unemployment Loss Sq\"]= data[\"Unemployment Rate\"].sub(unemployment_target).pow(2)\n",
    "data[\"Unemployment Loss Sq\"][data[\"Unemployment Loss\"] < 0] = data[\"Unemployment Loss Sq\"].mul(-1)\n",
    "\n",
    "\n",
    "\n",
    "data[\"Inflation Loss Diff\"]= data[\"Inflation Loss\"].diff(year)\n",
    "data[\"Unemployment Loss Diff\"]= data[\"Unemployment Loss\"].diff(year)\n",
    "data[\"Inflation Loss Sq Diff\"]= data[\"Inflation Loss Sq\"].diff(year)\n",
    "data[\"Unemployment Loss Sq Diff\"]= data[\"Unemployment Loss Sq\"].diff(year)\n",
    "\n",
    "\n",
    "\n",
    "data[\"Linear Loss\"] = data[\"Inflation Loss\"].sub(data[\"Unemployment Loss\"])\n",
    "data[\"Loss Function\"] = data[\"Inflation Loss Sq\"].sub(data[\"Unemployment Loss Sq\"])\n",
    "data[\"Linear Loss Diff\"] = data[\"Linear Loss\"].diff(year)\n",
    "data[\"Loss Function Diff\"] = data[\"Loss Function\"].diff(year)\n",
    "\n",
    "data[\"Real 1 Year Treasury Rate\"] = data[\"1 Year Treasury Rate (%)\"].sub(data[\"Inflation (CPI)\"])\n",
    "data[\"Real 3 Month Treasury Rate\"] = data[\"3 Month Treasury Rate (%)\"].sub(data[\"Inflation (CPI)\"])\n",
    "data[\"Real 1 Month Treasury Rate\"] = data[\"1 Month Treasury Rate (%)\"].sub(data[\"Inflation (CPI)\"])\n",
    "data[\"Real Effective Federal Funds Rate\"] = data['Effective Federal Funds Rate (%)'].sub(data[\"Inflation (CPI)\"])\n",
    "\n",
    "data[\"30 Year Minus 1 Year (%)\"] = data[\"30 Year Treasury Rate (%)\"].sub(data[\"1 Year Treasury Rate (%)\"])\n",
    "data[\"30 Year Minus 3 Month (%)\"] = data[\"30 Year Treasury Rate (%)\"].sub(data[\"3 Month Treasury Rate (%)\"])\n",
    "data[\"30 Year Minus 1 Month (%)\"] = data[\"30 Year Treasury Rate (%)\"].sub(data[\"1 Month Treasury Rate (%)\"])\n",
    "data[\"30 Year Minus Effective Federal Funds Rate\"] = data[\"30 Year Treasury Rate (%)\"].sub(data['Effective Federal Funds Rate (%)'])\n",
    "data[\"10 Year Minus 2 Year (%)\"] = data[\"10 Year Treasury Rate (%)\"].sub(data[\"2 Year Treasury Rate (%)\"])\n",
    "data[\"10 Year Minus 1 Year (%)\"] = data[\"10 Year Treasury Rate (%)\"].sub(data[\"1 Year Treasury Rate (%)\"])\n",
    "data[\"10 Year Minus 3 Month (%)\"] = data[\"10 Year Treasury Rate (%)\"].sub(data[\"3 Month Treasury Rate (%)\"])\n",
    "data[\"10 Year Minus 1 Month (%)\"] = data[\"10 Year Treasury Rate (%)\"].sub(data[\"1 Month Treasury Rate (%)\"])\n",
    "data[\"10 Year Minus Effective Federal Funds Rate\"] = data[\"10 Year Treasury Rate (%)\"].sub(data['Effective Federal Funds Rate (%)'])\n",
    "\n",
    "keys = list(data.keys())\n",
    "keys = [\"Date\"] + keys\n",
    "data[\"Date\"] = data.index.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TGO101': 'Percent Changes in Chain-Type Quantity Indexes for Gross Output by Industry',\n",
       " 'TGO103': 'Chain-Type Quantity Indexes for Gross Output by Industry',\n",
       " 'TGO104': 'Chain-Type Price Indexes for Gross Output by Industry',\n",
       " 'TGO105': 'Gross Output by Industry',\n",
       " 'TGO106': 'Real Gross Output by Industry',\n",
       " 'TGO107': 'Percent Changes in Chain-Type Price Indexes for Gross Output by Industry'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sheet_names = pd.ExcelFile('BEAGrossOutputbyindustryQuarterly.xlsx').sheet_names  # see all sheet names\n",
    "\n",
    "info = pd.read_excel(\"BEAGrossOutputbyindustryQuarterly.xlsx\", sheet_name = sheet_names[0], header = [3]).dropna(axis = 1)\n",
    "key_names = {}\n",
    "for ix in info.index:\n",
    "    row = info.loc[ix] \n",
    "    key, val = row.values[0], row.values[1]\n",
    "    key_names[key] = val\n",
    "key_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Percent Changes in Chain-Type Quantity Indexes for Gross Output by Industry', 'Chain-Type Quantity Indexes for Gross Output by Industry', 'Chain-Type Price Indexes for Gross Output by Industry', 'Gross Output by Industry', 'Real Gross Output by Industry', 'Percent Changes in Chain-Type Price Indexes for Gross Output by Industry'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_data = {}\n",
    "\n",
    "for sheet_name, variable in key_names.items():\n",
    "    sector_data[variable] = pd.read_excel(\"BEAGrossOutputbyindustryQuarterly.xlsx\", \n",
    "                            index_col = [1],\n",
    "                            sheet_name=sheet_name+\"-Q\", \n",
    "                            header = [7], parse_dates= True).T.iloc[2:].dropna(axis = 1)\n",
    "    sector_data[variable].rename(index = {ix:ix.replace(\"Q\",\"-\") for ix in sector_data[variable].index},\n",
    "                                inplace = True)\n",
    "    sector_data[variable].rename(index = {ix:ix[:-1] + (\"0\" + str(int(ix[-1]) * 3))[-2:] for ix in sector_data[variable].index},\n",
    "                                inplace = True)   \n",
    "    sector_data[variable].index = pd.DatetimeIndex(sector_data[variable].index)\n",
    "sector_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  Agriculture, forestry, fishing, and hunting',\n",
       " '  Mining',\n",
       " '  Utilities',\n",
       " '  Construction',\n",
       " '  Manufacturing',\n",
       " '  Wholesale trade',\n",
       " '  Retail trade',\n",
       " '  Transportation and warehousing',\n",
       " '  Information',\n",
       " '  Finance, insurance, real estate, rental, and leasing',\n",
       " '  Professional and business services',\n",
       " '  Educational services, health care, and social assistance',\n",
       " '  Arts, entertainment, recreation, accommodation, and food services',\n",
       " '  Other services, except government',\n",
       " '  Federal',\n",
       " '  State and local']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = ['Chain-Type Quantity Indexes for Gross Output by Industry',\n",
    "           'Chain-Type Price Indexes for Gross Output by Industry', \n",
    "           'Gross Output by Industry', \n",
    "           'Real Gross Output by Industry']\n",
    "\n",
    "layers = {}\n",
    "for index in indices:\n",
    "    data = sector_data[index]\n",
    "    layers[index] = {0:[],\n",
    "             1:{\"Private industries\":[], \"Government\":[]},\n",
    "             2:{}}\n",
    "    sector = \"Private industries\"\n",
    "    for key in sector_data[index].keys():\n",
    "        if key == \"Government\":\n",
    "            sector = \"Government\"\n",
    "        if key == key.strip():\n",
    "            layers[index][0].append(key)\n",
    "            subsector = key\n",
    "\n",
    "        elif key[:2] == \"  \" and key[:3] != \"   \":\n",
    "            layers[index][1][layers[index][0][-1]].append(key)\n",
    "\n",
    "#         elif key[:4] == \"    \" and key[:5] != \"     \":\n",
    "#             layers[index][2][layers[index][0][-1]].append(key)\n",
    "            \n",
    "layers    \n",
    "#     elif \"All industries\" not in key:\n",
    "#         layers[2][sector]\n",
    "#         .append(layers[0][-1] + \": \"+ layers[1][-1] + \": \" + key)\n",
    "private_and_public = layers['Chain-Type Quantity Indexes for Gross Output by Industry'][1][\"Private industries\"] + layers['Chain-Type Quantity Indexes for Gross Output by Industry'][1][\"Government\"]\n",
    "private_and_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-42b9201b41d0>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = df.index.astype(str).str[:4].astype(int)\n",
      "<ipython-input-5-42b9201b41d0>:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df[key].astype(float)\n",
      "<ipython-input-5-42b9201b41d0>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Date\"] = df.index.astype(str).str[:4].astype(int)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pingouin\n",
    "\n",
    "plt.rcParams.update({\"font.size\":24})\n",
    "vals = private_and_public\n",
    "for group in layers:\n",
    "\n",
    "    pp = PdfPages(group + \"LinePlots.pdf\")\n",
    "    df = sector_data[group]\n",
    "    keys = layers[group][1][\"Private industries\"] + layers[group][1][\"Government\"]\n",
    "    df = df[keys]\n",
    "    i = 0\n",
    "\n",
    "    for key in keys:\n",
    "        color = \"C\" + str(i)\n",
    "        color_df = df[[key]]\n",
    "        other_keys = [k for k in keys if k != key]\n",
    "        grey_df = df[other_keys]\n",
    "        fig, ax = plt.subplots(figsize = (30,30))\n",
    "        grey_df.plot.line(ax=ax, \n",
    "                          color = \"k\", \n",
    "                          alpha = .3, \n",
    "                          linewidth = 5, \n",
    "                          legend = False)\n",
    "        for other_key in other_keys:\n",
    "            plt.text(grey_df.index[-1], grey_df[other_key].iloc[-1], \n",
    "                     other_key, color = \"k\", alpha= .3)                \n",
    "        color_df.plot.line(ax = ax, color = color, linewidth = 10, legend = False)\n",
    "        plt.text(color_df.index[-1], color_df[key].iloc[-1], key, color = color, fontsize= 30)\n",
    "\n",
    "\n",
    "        i += 1\n",
    "        plt.title(group)\n",
    "        pp.savefig(fig, bbox_inches = \"tight\")  \n",
    "        plt.close()\n",
    "    pp.close()\n",
    "    pp = PdfPages(group + \"ScatterPlots.pdf\")\n",
    "\n",
    "    df[\"Date\"] = df.index.astype(str).str[:4].astype(int)    \n",
    "    for key1 in keys:\n",
    "        for key2 in keys:\n",
    "            if key1 != key2:\n",
    "                fig, ax = plt.subplots(figsize= (20,20))\n",
    "                im = ax.scatter(x = df[key1], y = df[key2], c = df[\"Date\"], \n",
    "                                cmap = \"viridis\", s = 50)\n",
    "                ax.set_xlabel(key1)\n",
    "                ax.set_ylabel(key2)\n",
    "                cbar = plt.colorbar(im)\n",
    "                cbar.ax.set_ylabel('Date')\n",
    "\n",
    "                pp.savefig(fig, bbox_inches = \"tight\")\n",
    "                plt.title(group)\n",
    "#                 plt.show()\n",
    "                plt.close()\n",
    "    pp.close()\n",
    "    corr_keys = list(df.keys())[:-1]\n",
    "    for key in corr_keys:\n",
    "        df[key] = df[key].astype(float)\n",
    "    df.corr().dropna().to_csv(group + \"CorrMatrix.csv\")\n",
    "    df.pcorr().dropna().to_csv(group + \"PcorrMatrix.csv\")\n",
    "\n",
    "        \n",
    "    \n",
    "#         series.plot(ax = ax, logy = False, legend = False, linewidth = 10)\n",
    "#         j = 0\n",
    "#         for key in series.keys():\n",
    "#             color = \"C\" + str(j)\n",
    "#             plt.text(series.index[-1], series[key].iloc[-1], key, color = color)\n",
    "#             j += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize = (30,30))\n",
    "#     i = 0\n",
    "#     df = sector_data[group]\n",
    "#     print(val)\n",
    "# #         print(val)\n",
    "#     keys = layers[group][1]\n",
    "#     for key, vals in keys.items():\n",
    "#         for val in vals:\n",
    "#             series = df[val]\n",
    "#             j = i % 10\n",
    "#             series.plot(ax = ax, logy = False, legend = False, linewidth = 10)\n",
    "#             plt.text(series.index[-1], series.iloc[-1], series.index.name, color = \"C\" + str(j))\n",
    "#             i+=1\n",
    "#     plt.title(group)\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "#     i = 0\n",
    "#     for key, val in layers[group][1].items():\n",
    "#         for series in val:\n",
    "#             fig, ax = plt.subplots(figsize = (30,30))\n",
    "#             for series2 in val:\n",
    "#                 if series2.keys() != series.keys():                    \n",
    "#                     series2.plot(ax = ax, logy = False, legend = False, color = \"k\", alpha = .3, linewidth = 5)\n",
    "#                     plt.text(series2.index[-1], series2.iloc[-1], series2.keys()[0], color = \"k\", alpha = .4)\n",
    "                \n",
    "#             j = i % 10\n",
    "#             color = \"C\" + str(j)\n",
    "#             series.plot(ax = ax, logy = False, legend = False, color = color, linewidth = 10)\n",
    "#             plt.text(series.index[-1], series.iloc[-1], series.keys()[0], color = color, size = 50)\n",
    "            \n",
    "            \n",
    "#             i+=1\n",
    "#             plt.title(group)\n",
    "#             plt.show()\n",
    "#             plt.close()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pingouin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from matplotlib.patches import Rectangle\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.base import DAG\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import networkx as nx\n",
    "plt.rcParams.update({\"font.size\":20})\n",
    "\n",
    "def graph_DAG(edges, df, title = \"\"):\n",
    "    pcorr = df.pcorr()\n",
    "    graph = nx.DiGraph()\n",
    "    edge_labels = {}\n",
    "    for edge in edges:\n",
    "        edge_labels[edge] = str(round(pcorr[edge[0]].loc[edge[1]],2))\n",
    "        \n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = [\"C7\" for g in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (30,30))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph, k = 5/(len(edge_labels.keys())**.5))\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size = 1200,\n",
    "                     with_labels=True,  arrows=True,\n",
    "                     #font_color = \"white\",\n",
    "                     font_size = 26, alpha = 1,\n",
    "                     width = 1, edge_color = \"C1\",\n",
    "                     arrowstyle=ArrowStyle(\"Fancy, head_length=3, head_width=1.5, tail_width=.1\"), ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph,pos,\n",
    "                                 edge_labels=edge_labels,\n",
    "                                 font_color='green',\n",
    "                                 font_size=20)\n",
    "    \n",
    "def calculate_pcorr(data, keys):\n",
    "    pcorr_df = data[keys]\n",
    "\n",
    "    pcorr_dct = {}\n",
    "    p_val_dct = {}\n",
    "    for key1 in keys:\n",
    "        p_val_dct[key1] = {}\n",
    "        pcorr_dct[key1] = {}\n",
    "        for key2 in keys:\n",
    "            if key1 != key2:\n",
    "                other_vars = [z for z in pcorr_df.keys() if z != key1 and z != key2 ]\n",
    "                stats = pingouin.partial_corr(data=pcorr_df, \n",
    "                                              x = key1, \n",
    "                                              y = key2, \n",
    "                                              covars=other_vars)\n",
    "                p_val_dct[key1][key2] = stats[\"p-val\"].values[0]\n",
    "\n",
    "                pcorr_dct[key1][key2] = pcorr_df.pcorr()[key1][key2]\n",
    "            else:\n",
    "                p_val_dct[key1][key2] = 1\n",
    "                pcorr_dct[key1][key2] = 1\n",
    "\n",
    "    p_val_df = pd.DataFrame(p_val_dct)\n",
    "    pcorr_df = pd.DataFrame(pcorr_dct)\n",
    "    return pcorr_df, p_val_df\n",
    "\n",
    "\n",
    "for group in layers:\n",
    "    pp = PdfPages(group + \"corrPlots.pdf\")\n",
    "    df = sector_data[group]\n",
    "    keys = layers[group][1][\"Private industries\"] + layers[group][1][\"Government\"]\n",
    "    df = df[keys].pct_change(4)\n",
    "    pcorr_df, p_val_df = calculate_pcorr(df, keys)\n",
    "\n",
    "    plot_df = pcorr_df.dropna()\n",
    "    plot_pvals_df = p_val_df.dropna()\n",
    "\n",
    "    sig_vals = [.05, .01, .001]\n",
    "    for key in plot_df:\n",
    "        plot_df[key] = plot_df[key].round(3).astype(str)\n",
    "        #plot_pvals_df[key] = plot_pvals_df[key].astype(str)\n",
    "        for ix in plot_df.index:\n",
    "            value = plot_df.loc[ix, key]\n",
    "            p_val = plot_pvals_df.loc[ix, key]\n",
    "            for sig_val in sig_vals:\n",
    "                if p_val < sig_val: \n",
    "                    plot_df.loc[ix,key] = plot_df.loc[ix, key] + \"*\"\n",
    "\n",
    "    plot_df = pcorr_df.dropna()\n",
    "\n",
    "    plt.rcParams.update({'font.size': 20}) \n",
    "\n",
    "    # pcorr_df.style.use(p_val_df.style.applymap(bold_sig).export())\n",
    "    fig, ax = plt.subplots(figsize = (50,50))\n",
    "    mx = np.abs(pcorr_df.max().max())\n",
    "    mn = np.abs(pcorr_df.min().min())\n",
    "    max_val = max([mx,mn])\n",
    "    min_val = max_val * -1\n",
    "    pcorr_plot_df = plot_df.rename(columns = {key:key.replace(\"  \", \"\").replace(\" \", \"\\n\") for key in plot_df.keys()}, index = {ix:ix.replace(\"  \", \"\").replace(\" \", \"\\n\") for ix in plot_df.index})\n",
    "    \n",
    "    countries = plot_df.index\n",
    "    keys = plot_df.keys()\n",
    "    mp = sn.heatmap(pcorr_plot_df, annot = True, linewidth=1,cmap = \"seismic\", ax=ax, vmin=min_val, vmax=max_val)\n",
    "    plt.title(\"Partial Correlation\\n\"+group, fontsize = 50)\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(len(countries)):\n",
    "            key = keys[i]\n",
    "            country = countries[j]\n",
    "            p_val = p_val_df.loc[country][key]\n",
    "            lw = 0\n",
    "            for k in range(len(sig_vals)):\n",
    "                sig_val = sig_vals[k]\n",
    "                if p_val <= sig_val:\n",
    "                    lw = 3 * (k + 1) ** 2\n",
    "    #         anchor = (lw / 2, lw / 2)\n",
    "            mp.add_patch(Rectangle((i, j), 1, 1, fill=False, edgecolor='k', lw=lw))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    dag_df = df.dropna().rename(\n",
    "        columns={\n",
    "            col:col.replace(\"  \", \"\").replace(\" \", \"\\n\") for col in dag_df.keys()})\n",
    "    variant = \"parallel\"\n",
    "    sig = 0.0005\n",
    "    ci_test = \"pearsonr\"\n",
    "    keys = dag_df.keys()\n",
    "    c = PC(dag_df)\n",
    "    max_cond_vars = len(keys) - 2\n",
    "    model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                       significance_level = sig, \n",
    "                       max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "    edges = model.edges()\n",
    "    graph_DAG(edges, dag_df, title = group)    \n",
    "# pcorr_df[p_val_df[\"General Outcome\"] < sig]#.style.apply(highlight)\n",
    "# pcorrsig[p_val_df[\"General Outcome\"] < sig].to_csv(\"StatisticallySignificantOutcomesbyCountry.csv\")\n",
    "# p_val_df[p_val_df[\"General Outcome\"] < sig].to_csv(\"StatisticalSignificancebyCountry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_datareader.data as web\n",
    "# start = datetime.datetime(2001, 12, 1)\n",
    "# end = datetime.datetime.today()\n",
    "# x =  web.DataReader(\"CPIAUCSL\", \"fred\", start, end).resample(freq).mean().pct_change(year).mul(100).dropna()\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yfin\n",
    "yfin.pdr_override()\n",
    "data[\"S&P\"]= web.get_data_yahoo(ticker, start = start, end = end).resample(freq).mean()[\"Close\"].iloc[:-2]\n",
    "data[\"S&P Growth Rate (%)\"] = data[\"S&P\"].pct_change(year)\n",
    "data[\"S&P Growth Rate Change Diff (%)\"] = data[\"S&P Growth Rate (%)\"].diff(year)\n",
    "data[\"Real S&P Growth Rate (%)\"] = data[\"S&P Growth Rate (%)\"].sub(data[\"Inflation (CPI)\"])\n",
    "data[\"VIX Diff\"] = data[\"VIX\"].diff(year)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fedProject\n",
    "# . . . \n",
    "data[\"Balance Sheet: Direct Lending and Central Bank Liquidity Swaps\"] =\\\n",
    "    data[\"Balance Sheet: Central Bank Liquidity Swaps ($ Mil)\"].add(\n",
    "    data[\"Balance Sheet: Direct Lending ($ Mil)\"])\n",
    "data[\"Balance Sheet: Other Securities\"] = data[\"Balance Sheet: Securities Held Outright ($ Mil)\"].sub(\n",
    "    data[\"Balance Sheet: U.S. Treasuries Held Outright ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Mortgage-Backed Securities ($ Mil)\"])\n",
    "data[\"Balance Sheet: Other Assets\"] = data[\"Balance Sheet: Total Assets ($ Mil)\"].sub(\n",
    "    data[\"Balance Sheet: Securities Held Outright ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Direct Lending and Central Bank Liquidity Swaps\"]).sub(\n",
    "    data[\"Balance Sheet: Repos ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Unamortized Security Premiums ($ Mil)\"])\n",
    "data[\"Balance Sheet: Other Deposits ($ Mil)\"] = data[\"Balance Sheet: All Deposits ($ Mil)\"].sub(\n",
    "    data[\"Balance Sheet: U.S. Treasury General Account ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Deposits from Dep. Institutions ($ Mil)\"])\n",
    "data[\"Balance Sheet: Other Liabilities\"]= data[\"Balance Sheet: Total Liabilities ($ Mil)\"].sub(\n",
    "    data[\"Balance Sheet: Federal Reserve Notes Outstanding ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: U.S. Treasury General Account ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Deposits from Dep. Institutions ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Other Deposits ($ Mil)\"]).sub(\n",
    "    data[\"Balance Sheet: Reverse Repos ($ Mil)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\":32})\n",
    "interest_vars = [\"Effective Federal Funds Rate (%)\",\n",
    "                   \"Interest on Reserves (%)\",\n",
    "                   \"1 Month Treasury Rate (%)\"]\n",
    "fig, ax = plt.subplots(figsize = (30,20))\n",
    "data[interest_vars].plot.line(legend=True, linewidth = 3, ax = ax)\n",
    "y_vals = ax.get_yticks()\n",
    "ax.set_yticklabels([str(round(y,2))+ \"%\" for y in y_vals])  \n",
    "ax.set_title(\"Short Term Interest Rates\", fontsize = 48)\n",
    "data[[\"Date\"] + interest_vars].to_json(\"shortTermRates.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {\n",
    "    key: key.replace(\"Balance Sheet: \", \"\").replace(\" ($ Mil)\", \"\").replace(\"Base: \",\"\") for key in data.keys()})\n",
    "keys = list(data.keys())\n",
    "interest_rates = [\"Effective Federal Funds Rate (%)\",\n",
    "                   \"Interest on Reserves (%)\",\n",
    "                   \"1 Month Treasury Rate (%)\"]\n",
    "plot_data = data.copy()\n",
    "for key, val in data.items():\n",
    "    if key not in interest_rates:\n",
    "        try:\n",
    "            plot_data[key] = val.div(10**6)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_vars = [\"U.S. Treasuries Held Outright\",\n",
    "               \"Mortgage-Backed Securities\",\n",
    "               \"Other Securities\",\n",
    "               \"Direct Lending and Central Bank Liquidity Swaps\",\n",
    "               \"Repos\",\n",
    "               \"Unamortized Security Premiums\",\n",
    "               \"Other Assets\"]\n",
    "figsize= (36,18)\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plot_data[account_vars].plot.area(stacked = True, linewidth = 3,\n",
    "                            ax = ax)\n",
    "# change y vals from mil to tril\n",
    "total_var = \"Total Assets\"\n",
    "plot_data[total_var].plot.line(linewidth = 1, \n",
    "                             ax = ax, c = \"k\",\n",
    "                             label = total_var, ls = \"--\")\n",
    "plt.xticks(rotation = 90)\n",
    "ax.legend(loc=2, ncol = 2)\n",
    "ax.set_ylabel(\"$ Trillion\", fontsize = 40)\n",
    "ax.set_title(\"Federal Reserve Balance Sheet: Assets\", fontsize = 50)\n",
    "plot_data[[total_var] + account_vars].to_csv(\"FederalReserveAssets.csv\")\n",
    "plot_data[[\"Date\"] + account_vars].to_json(\"fedAssets.json\", orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_vars = [\"Federal Reserve Notes Outstanding\",\n",
    "                \"U.S. Treasury General Account\",\n",
    "                \"Deposits from Dep. Institutions\",\n",
    "                \"Other Deposits\",\n",
    "                \"Reverse Repos\",\n",
    "                \"Other Liabilities\"]\n",
    "total_var = \"Total Liabilities\"\n",
    "\n",
    "plot_stacked_lines(\n",
    "    plot_data,\n",
    "    account_vars, linewidth = 1,\n",
    "    total_var = \"Total Liabilities\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize= (36,18)\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plot_data[account_vars].plot.area(stacked = True, linewidth = 3,\n",
    "                            ax = ax)\n",
    "# change y vals from mil to tril\n",
    "total_var = \"Total Liabilities\"\n",
    "plot_data[total_var].plot.line(linewidth = 2, \n",
    "                             ax = ax, c = \"k\",\n",
    "                             label = total_var, ls = \"--\")\n",
    "plt.xticks(rotation = 90)\n",
    "ax.legend(loc=2, ncol = 2)\n",
    "ax.set_ylabel(\"$ Trillion\", fontsize = 40)\n",
    "ax.set_title(\"Federal Reserve Balance Sheet: Liabilities\", fontsize = 50)\n",
    "plot_data[[total_var] + account_vars].to_csv(\"FederalReserveLiabilities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\":32})\n",
    "df = plot_data.copy()\n",
    "for key in account_vars:\n",
    "    df[key] = df[key].div(df[\"Total Liabilities\"])\n",
    "figsize= (36,18)\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "df[account_vars].plot.area(stacked = True, linewidth = 3,\n",
    "                            ax = ax)\n",
    "plt.xticks(rotation= 90, fontsize = 45)\n",
    "ax.set_yticklabels([str(int(val * 100)) + \"% \" for val in ax.get_yticks()], fontsize = 45)\n",
    "\n",
    "#plt.yticks([int(tick * 100) for tick in ax.get_yticks() if tick <1.01])\n",
    "plt.title(\"Liabilities as a Proportion of the\\nFederal Reserve's Balance Sheet\", fontsize =45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data[\"Net Effect on Overnight Lending Market\"] =\\\n",
    "    plot_data[\"Repos\"].sub(plot_data[\"Reverse Repos\"])\n",
    "overnight_vars = [\"Repos\",\n",
    "                  \"Reverse Repos\",\n",
    "                  \"Net Effect on Overnight Lending Market\"]\n",
    "fig, ax = plt.subplots(figsize = (30,20))\n",
    "plot_data[overnight_vars].plot.line(legend=True, linewidth = 3, ax = ax)\n",
    "ax.set_ylabel(\"$ Trillion\", fontsize = 40)\n",
    "ax.set_title(\"Federal Reserve Activity\\nin Overnight Lending Market\", fontsize = 48)\n",
    "plot_data[[\"Date\"] + overnight_vars].to_json(\"overnightLending.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Total Liabilities Growth Rate (%)\"] = data[\"Total Liabilities\"].pct_change(year)\n",
    "data[\"Total Assets Growth Rate (%)\"] = data[\"Total Assets\"].pct_change(year)\n",
    "data[\"Total Liabilities / Currency in Circulation\"] = data[\"Total Liabilities\"].div(data[\"Currency in Circulation ($ Bil)\"].mul(1000))\n",
    "data[\"Total Assets / Currency in Circulation\"] = data[\"Total Assets\"].div(data[\"Currency in Circulation ($ Bil)\"].mul(1000))\n",
    "data[\"Currency in Circulation / Total Assets\"] = data[\"Currency in Circulation ($ Bil)\"].mul(1000).div(data[\"Total Assets\"])\n",
    "data[\"Currency in Circulation / Total Assets Diff\"] = data[\"Currency in Circulation / Total Assets\"].diff(year)\n",
    "data[\"Currency in Circulation / Total Liabilities\"] = data[\"Currency in Circulation ($ Bil)\"].mul(1000).div(data[\"Total Liabilities\"])\n",
    "data[\"Currency in Circulation / Total Liabilities Diff\"] = data[\"Currency in Circulation / Total Liabilities\"].diff(year)\n",
    "\n",
    "data[\"Log Total Liabilities\"] = np.log(data[\"Total Liabilities\"])\n",
    "data[\"Log Total Assets\"] = np.log(data[\"Total Assets\"])\n",
    "#data[\"Currency in Circulation / Total Liabilities %\"] = data[\"Currency in Circulation / Total Liabilities\"].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin\n",
    "plot_vars = [\"Inflation (PCE)\",\n",
    "             \"Unemployment Rate\",\n",
    "             \"Inflation Loss\",\n",
    "             \"Unemployment Loss\",\n",
    "             \"Linear Loss\",\n",
    "             \"Loss Function\",\n",
    "             \"Effective Federal Funds Rate (%)\",\n",
    "             \"Currency in Circulation Growth Rate (%)\",\n",
    "             \"Currency in Circulation / Total Assets\",\n",
    "             \"Total Assets Growth Rate (%)\"]\n",
    "#data[plot_vars].describe().T.to_excel(\"C:\\\\Users\\\\JLCat\\\\OneDrive\\\\Documents\\\\For NDSU\\\\Projects\\\\Sound Money Project\\\\Frederal Reserve QE Framework\\\\DescriptionStatistics.xls\")\n",
    "#data[plot_vars].describe().corr()\n",
    "#data[plot_vars].describe().pcorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vars = [#Currency in Circulation Growth Rate (%)\",\n",
    "             #\"Currency not in Circulation Growth Rate (%)\",\n",
    "             #\"5 Year Forward Rate\",\n",
    "             #\"Inflation (CPI)\",\n",
    "             #\"Unemployment Rate Diff\",\n",
    "             #\"Loss Function Diff\",\n",
    "            #\"Unemployment Loss Diff\",\n",
    "            #\"Inflation Loss Diff\",\n",
    "            #\"Linear Loss Diff\",\n",
    "            #\"Unemployment Loss Sq Diff\",\n",
    "            #\"Inflation Loss Sq Diff\",\n",
    "            \"Linear Loss Diff\",\n",
    "    #\"Currency in Circulation % Change Velocity\",\n",
    "             #\"Nominal GDP Growth Rate (%)\",\n",
    "             #\"Real GDP Growth Rate (%)\",\n",
    "             \"Effective Federal Funds Rate Diff (%)\",\n",
    "             #\"30 Year Treasury Rate (%)\",\n",
    "             #\"1 Month Treasury Rate (%)\",\n",
    "             #\"S&P Growth Rate (%)\",\n",
    "             \"Currency in Circulation / Total Assets Diff\",\n",
    "             #Total Assets Growth Rate (%)\",\n",
    "             \"VIX Diff\"\n",
    "]\n",
    "dag_df = data[plot_vars].dropna().rename(columns={key: key.replace(\" \", \"\\n\") for key in plot_vars}).loc[\"2008-10-01\":\"2020-08-01\"]\n",
    "dag_df.pcorr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plot_vars_dct = {0: [\"Loss Function Diff\",\n",
    "                     \"Effective Federal Funds Rate Diff (%)\",\n",
    "                     \"Currency in Circulation / Total Assets Diff\"],\n",
    "#                     \"VIX Diff\"],\n",
    "                 1:[\"Currency in Circulation Growth Rate (%)\",\n",
    "                    \"Loss Function Diff\",\n",
    "                    \"Effective Federal Funds Rate Diff (%)\",\n",
    "                    \"Total Assets Growth Rate (%)\"],\n",
    " #                   \"VIX Diff\"],\n",
    "                 2:[\"Unemployment Loss Sq Diff\",\n",
    "                    \"Inflation Loss Sq Diff\",\n",
    "                    \"Effective Federal Funds Rate Diff (%)\",\n",
    "                    \"Currency in Circulation / Total Assets Diff\"],\n",
    "#                    \"VIX Diff\"],\n",
    "                 3:[\"Currency in Circulation Growth Rate (%)\",\n",
    "                    \"Unemployment Loss Sq Diff\",\n",
    "                    \"Inflation Loss Sq Diff\",\n",
    "                    \"Effective Federal Funds Rate Diff (%)\",\n",
    "                    \"Total Assets Growth Rate (%)\"],\n",
    "                    #\"VIX Diff\"]\n",
    "}\n",
    "\n",
    "sig = 0.01\n",
    "variant = \"parallel\"\n",
    "ci_test = \"pearsonr\"\n",
    "for key, plot_vars in plot_vars_dct.items():\n",
    "    dfs = {\"2008-10-31 to 2020-07-31\": data[plot_vars].dropna().rename(columns={key: key.replace(\" \", \"\\n\") for key in plot_vars}).loc[\"2008-10-31\":\"2020-08-31\"],\n",
    "           \"2003-12-31 to 2008-09-30\": data[plot_vars].dropna().rename(columns={key: key.replace(\" \", \"\\n\") for key in plot_vars}).loc[:\"2008-09-30\"]}\n",
    "           \n",
    "    for dates, dag_df in dfs.items():\n",
    "\n",
    "        keys = dag_df.keys()\n",
    "        c = PC(dag_df.dropna())\n",
    "        max_cond_vars = len(keys) - 2\n",
    "#         print(dag_df.index)\n",
    "\n",
    "        model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                           significance_level = sig, \n",
    "                           max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "        edges = model.edges()\n",
    "        pcorr = dag_df.pcorr()\n",
    "        weights = {}\n",
    "#         for edge in edges:\n",
    "#             print(edge, \":\",pcorr[edge[0]].loc[edge[1]])\n",
    "#         skel, sep_sets = c.build_skeleton(variant = variant, ci_test = ci_test, significance_level = sig, \n",
    "#                            max_cond_vars = max_cond_vars)\n",
    "\n",
    "\n",
    "        graph_DAG(edges, dag_df, title = dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "from pgmpy.base import DAG\n",
    "\n",
    "keys = dag_df.keys()\n",
    "c = PC(dag_df.dropna())\n",
    "max_cond_vars = len(keys) - 2\n",
    "\n",
    "sig = 0.05\n",
    "variant = \"parallel\"\n",
    "ci_test = \"pearsonr\"\n",
    "model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                   significance_level = sig, \n",
    "                   max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "\n",
    "edges = model.edges()\n",
    "pcorr = dag_df.pcorr()\n",
    "weights = {}\n",
    "for edge in edges:\n",
    "    print(edge, \":\",pcorr[edge[0]].loc[edge[1]])\n",
    "skel, sep_sets = c.build_skeleton(variant = variant, ci_test = ci_test, significance_level = 0.01, \n",
    "                   max_cond_vars = max_cond_vars)\n",
    "sep_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import networkx as nx\n",
    "plt.rcParams.update({\"font.size\":20})\n",
    "\n",
    "def graph_DAG(edges, df, title = \"\"):\n",
    "    pcorr = df.pcorr()\n",
    "    graph = nx.DiGraph()\n",
    "    edge_labels = {}\n",
    "    for edge in edges:\n",
    "        edge_labels[edge] = str(round(pcorr[edge[0]].loc[edge[1]],2))\n",
    "        \n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = [\"C0\" for g in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,20))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)#, k = 5/(len(sig_corr.keys())**.5))\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size = 1200,\n",
    "                     with_labels=True,  arrows=True,\n",
    "                     #font_color = \"white\",\n",
    "                     font_size = 26, alpha = 1,\n",
    "                     width = 1, edge_color = \"C1\",\n",
    "                     arrowstyle=ArrowStyle(\"Fancy, head_length=3, head_width=1.5, tail_width=.1\"), ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph,pos,\n",
    "                                 edge_labels=edge_labels,\n",
    "                                 font_color='green',\n",
    "                                 font_size=20)\n",
    "\n",
    "graph_DAG(edges, dag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "from pgmpy.base import DAG\n",
    "\n",
    "keys = dag_df.keys()\n",
    "c = PC(dag_df.dropna())\n",
    "max_cond_vars = len(keys) - 2\n",
    "\n",
    "variant = \"parallel\"\n",
    "ci_test = \"pearsonr\"\n",
    "model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                   significance_level = sig, \n",
    "                   max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "\n",
    "edges = model.edges()\n",
    "pcorr = dag_df.pcorr()\n",
    "weights = {}\n",
    "for edge in edges:\n",
    "    print(edge, \":\",pcorr[edge[0]].loc[edge[1]])\n",
    "skel, sep_sets = c.build_skeleton(variant = variant, ci_test = ci_test, significance_level = 0.01, \n",
    "                   max_cond_vars = max_cond_vars)\n",
    "sep_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_DAG(edges, dag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "from pgmpy.base import DAG\n",
    "\n",
    "keys = dag_df.keys()\n",
    "c = PC(dag_df.dropna())\n",
    "max_cond_vars = len(keys) - 2\n",
    "\n",
    "variant = \"parallel\"\n",
    "ci_test = \"pearsonr\"\n",
    "model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                   significance_level = sig, \n",
    "                   max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "\n",
    "edges = model.edges()\n",
    "pcorr = dag_df.pcorr()\n",
    "weights = {}\n",
    "for edge in edges:\n",
    "    print(edge, \":\",pcorr[edge[0]].loc[edge[1]])\n",
    "skel, sep_sets = c.build_skeleton(variant = variant, ci_test = ci_test, significance_level = 0.01, \n",
    "                   max_cond_vars = max_cond_vars)\n",
    "sep_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_DAG(edges, dag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "from pgmpy.base import DAG\n",
    "\n",
    "keys = dag_df.keys()\n",
    "c = PC(dag_df.dropna())\n",
    "max_cond_vars = len(keys) - 2\n",
    "\n",
    "variant = \"parallel\"\n",
    "ci_test = \"pearsonr\"\n",
    "model = c.estimate(return_type = \"dag\",variant= variant, \n",
    "                   significance_level = sig, \n",
    "                   max_cond_vars = max_cond_vars, ci_test = ci_test)\n",
    "\n",
    "edges = model.edges()\n",
    "pcorr = dag_df.pcorr()\n",
    "weights = {}\n",
    "for edge in edges:\n",
    "    print(edge, \":\",pcorr[edge[0]].loc[edge[1]])\n",
    "skel, sep_sets = c.build_skeleton(variant = variant, ci_test = ci_test, significance_level = 0.01, \n",
    "                   max_cond_vars = max_cond_vars)\n",
    "sep_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sep_sets:\n",
    "    print(list(sep_sets[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_DAG(edges, dag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import networkx as nx\n",
    "plt.rcParams.update({\"font.size\":20})\n",
    "\n",
    "def graph_DAG(edges, df,sep_sets, title = \"\"):\n",
    "    graph = nx.DiGraph()\n",
    "    edge_labels = {}\n",
    "    pcorr = df.pcorr()\n",
    "    for edge in sep_sets:\n",
    "        sep_set = list(sep_sets[edge])\n",
    "        key = list(edge)\n",
    "#        pcorr = df[key + sep_set].pcorr()\n",
    "        edge_labels[edge] = str(round(pcorr[key[0]].loc[key[1]],2))\n",
    "    print(edge_labels)\n",
    "    graph.add_edges_from(sep_sets.keys())\n",
    "    color_map = [\"C0\" for g in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,20))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)#, k = 5/(len(sig_corr.keys())**.5))\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size = 1200,\n",
    "                     with_labels=True,  arrows=True,\n",
    "                     #font_color = \"white\",\n",
    "                     font_size = 26, alpha = 1,\n",
    "                     width = 1, edge_color = \"C1\",\n",
    "                     arrowstyle=ArrowStyle(\"Fancy, head_length=3, head_width=1.5, tail_width=.1\"), ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph,pos,\n",
    "                                 edge_labels=edge_labels,\n",
    "                                 font_color='green',\n",
    "                                 font_size=20)\n",
    "\n",
    "graph_DAG(edges, dag_df, sep_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20,12)\n",
    "fig,ax = plt.subplots(figsize = figsize)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax3 = ax.twinx()\n",
    "data[[\"Currency in Circulation / Total Assets\"]].plot(legend = False, \n",
    "                                                      linewidth = 5, \n",
    "                                                      alpha = .8,\n",
    "                                                      ax = ax)\n",
    "data[[\"Effective Federal Funds Rate (%)\"]].plot(legend = False, \n",
    "                                                      linewidth = 5, \n",
    "                                                      alpha = .8,\n",
    "                                                      ax = ax2,\n",
    "                                                        c = \"C1\")\n",
    "data[[\"Linear Loss\"]].iloc[:-1].plot(legend = False, \n",
    "                                                      linewidth = 5, \n",
    "                                                      alpha = .1,\n",
    "                                                      ax = ax3,\n",
    "                                                        c = \"k\")\n",
    "\n",
    "ax.set_yticklabels([str(int(val * 100)) + \"%\" for val in ax.get_yticks()], c = \"C0\")\n",
    "ax2.set_yticklabels([str(int(val)) + \"%\" for val in ax2.get_yticks()], c = \"C1\")\n",
    "ax3.set_yticklabels(ax3.get_yticks(), alpha = .2, c = \"k\")\n",
    "ax3.set_yticks([])\n",
    "\n",
    "ax3.axhline(0, c = \"k\", alpha = .1, linewidth = 5, ls = \"--\")\n",
    "\n",
    "plt.axvline(datetime.datetime(2008,10,1), c = \"k\", ls = \"--\", alpha = .9)\n",
    "ax.text(datetime.datetime(2013,3,1), .42, \"Currency in Circulation\\n/  \\nTotal Assets\", fontsize = 25, c = \"C0\", \n",
    "        ha = \"center\")\n",
    "ax.text(datetime.datetime(2018,5,1), .58, \"Effective\\nFederal\\nFunds\\nRate\", fontsize = 25, c = \"C1\", \n",
    "        ha = \"center\")\n",
    "ax.text(datetime.datetime(2014,6,1), .78, \"Linear\\nLoss\\nFunction\", fontsize = 25, c = \"k\", alpha = .3, \n",
    "        ha = \"center\")\n",
    "ax.text(datetime.datetime(2002,10,1), .955, \"0\", fontsize = 30, c = \"k\", alpha = .3, \n",
    "        ha = \"right\")\n",
    "ax.text(datetime.datetime(2022,1,1), .955, \"0 \", fontsize = 30, c = \"k\", alpha = .3, \n",
    "        ha = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (30,15))\n",
    "data[[\"Linear Loss Diff\", \"Total Assets Growth Rate (%)\"]].plot.scatter(x = \"Linear Loss Diff\", y = \"Total Assets Growth Rate (%)\", ax = ax)\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (30,15))\n",
    "data.iloc[:-1].plot.scatter(x = \"Linear Loss\", y = \"Currency in Circulation / Total Assets\", ax = ax)\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
