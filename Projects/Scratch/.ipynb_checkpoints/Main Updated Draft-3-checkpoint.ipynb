{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478aebdf",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81cdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import io, base64, os, json, re\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import matplotlib.transforms as mtransforms\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f2986",
   "metadata": {},
   "source": [
    "# Fred Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d21ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(data_codes, start, \n",
    "                end = datetime.datetime.today(), freq = \"M\"):\n",
    "    i = 0\n",
    "    # dct.items() calls key and value that key points to\n",
    "    for key, val in data_codes.items():\n",
    "        if i == 0:\n",
    "            # Create dataframe for first variable, then rename column\n",
    "            df = web.DataReader(val, \"fred\", start, end).resample(freq).mean()\n",
    "            df.rename(columns = {val:key}, inplace = True) \n",
    "            # setting i to None will cause the next block of code to execute,\n",
    "            # placing data within df instead of creating a new dataframe for\n",
    "            # each variable\n",
    "            i = None\n",
    "        else:\n",
    "            # If dataframe already exists, add new column\n",
    "            df[key] = web.DataReader(val, \"fred\", start, end).resample(freq).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865a35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_codes  = {\"Base: Total ($ Mil)\": \"BOGMBASE\",\n",
    "               \"Base: Currency in Circulation ($ Mil)\": \"WCURCIR\",\n",
    "               # Assets\n",
    "               \"Balance Sheet: Total Assets ($ Mil)\": \"WALCL\",\n",
    "               \"Balance Sheet Securities, Prem-Disc, Repos, and Loans ($ Mil)\": \"WSRLL\",\n",
    "               \"Balance Sheet: Securities Held Outright ($ Mil)\": \"WSHOSHO\",\n",
    "               ### breakdown of securities holdings ###\n",
    "               \"Balance Sheet: U.S. Treasuries Held Outright ($ Mil)\":\"WSHOTSL\",\n",
    "               \"Balance Sheet: Federal Agency Debt Securities ($ Mil)\" : \"WSHOFADSL\",\n",
    "               \"Balance Sheet: Mortgage-Backed Securities ($ Mil)\": \"WSHOMCB\",\n",
    "               # other forms of lending\n",
    "               \"Balance Sheet: Repos ($ Mil)\": \"WORAL\",\n",
    "               \"Balance Sheet: Central Bank Liquidity Swaps ($ Mil)\" : \"SWPT\",\n",
    "               \"Balance Sheet: Direct Lending ($ Mil)\" : \"WLCFLL\",\n",
    "               # unamortized value of securities held (due to changes in interest rates)\n",
    "               \"Balance Sheet: Unamortized Security Premiums ($ Mil)\": \"WUPSHO\",\n",
    "               # Liabilities\n",
    "               \"Balance Sheet: Total Liabilities ($ Mil)\" : \"WLTLECL\",\n",
    "               \"Balance Sheet: Federal Reserve Notes Outstanding ($ Mil)\" : \"WLFN\",\n",
    "               \"Balance Sheet: Reverse Repos ($ Mil)\": \"WLRRAL\",\n",
    "               ### Major share of deposits \n",
    "               \"Balance Sheet: Excess Reserves ($ Mil)\": \"EXCSRESNW\",\n",
    "               \"Balance Sheet: Required Reserves ($ Mil)\": \"RESBALREQW\",\n",
    "               \"Balance Sheet: Total Reserves ($ Mil)\": \"WRESBAL\",\n",
    "               \"Balance Sheet: Deposits from Dep. Institutions ($ Mil)\":\"WLODLL\",\n",
    "               \"Balance Sheet: U.S. Treasury General Account ($ Mil)\": \"WDTGAL\",\n",
    "               \"Balance Sheet: Other Deposits ($ Mil)\": \"WOTHLB\",\n",
    "               \"Balance Sheet: All Deposits ($ Mil)\": \"WLDLCL\",\n",
    "               # Interest Rates\n",
    "               \"Federal Funds Target (Pre-Crisis)\": \"DFEDTAR\",\n",
    "               \"Federal Funds (Upper) Target\":\"DFEDTARU\",\n",
    "               \"Effective Federal Funds Rate\":\"DFF\",\n",
    "               \"Interest on Excess Reserves\":\"IOER\",\n",
    "               # Req Reserves and Vault Cash\n",
    "               \"Vault Cash ($ Mil)\": \"TLVAULTW\",\n",
    "               \"Vault Cash Used as Req. ($ Mil)\": \"VAULT\",\n",
    "               }\n",
    "               \n",
    "# Select start and end dates\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "# freq refers to data frequency. Choose \"D\", \"W\", \"M\", \"Q\", \"A\"\n",
    "# a number may also be place in front of a letter. \"2D\" indicates\n",
    "#       alternating days\n",
    "fed_data = gather_data(data_codes = data_codes, start = start, \n",
    "                   end = end, freq = \"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e030882",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9327fdc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data 1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d7805fe5bf1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data 1.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data 1.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"data 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2178ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93475db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.drop(['Base: Currency in Circulation ($ Mil)', 'Balance Sheet: Total Assets ($ Mil)', 'Adj Close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29701c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e777059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_new.loc['1/31/2009':'10/31/2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0492eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stock =  data_new.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b2d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_updated = data_stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c943f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa75ad",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_updated.drop('Log Stock Price', axis = 1)\n",
    "Y = data_updated[['Log Stock Price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "\n",
    "regression_model.fit(X_train, y_train)\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "         normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2f4e3",
   "metadata": {},
   "source": [
    "# Exploring the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18616ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab the coefficient of our model and the intercept\n",
    "intercept = regression_model.intercept_[0]\n",
    "coefficent = regression_model.coef_[0][0]\n",
    "\n",
    "print(\"The intercept for our model is {:.4}\".format(intercept))\n",
    "print('-'*100)\n",
    "\n",
    "# loop through the dictionary and print the data\n",
    "for coef in zip(X.columns, regression_model.coef_[0]):\n",
    "    print(\"The Coefficient for {} is {:.2}\".format(coef[0],coef[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382ea54",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our intput\n",
    "X2 = sm.add_constant(X)\n",
    "\n",
    "# create a OLS model\n",
    "model = sm.OLS(Y, X2)\n",
    "\n",
    "# fit the data\n",
    "est = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88873734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple predictions\n",
    "y_predict = regression_model.predict(X_test)\n",
    "\n",
    "# Show the first 5 predictions\n",
    "y_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cda61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our intput\n",
    "X2 = sm.add_constant(X)\n",
    "\n",
    "# create a OLS model\n",
    "model = sm.OLS(Y, X2)\n",
    "\n",
    "# fit the data\n",
    "est = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83310a55",
   "metadata": {},
   "source": [
    "## Checking for Heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pval, __, f_pval = diag.het_breuschpagan(est.resid, est.model.exog)\n",
    "print(pval, f_pval)\n",
    "print('-'*100)\n",
    "\n",
    "# print the results of the test\n",
    "if pval > 0.05:\n",
    "    print(\"For the Breusch-Pagan's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We fail to reject the null hypthoesis, so there is no heterosecdasticity.\")\n",
    "\n",
    "else:\n",
    "    print(\"For the Breusch-Pagan's Test\")\n",
    "    print(\"The p-value was {:.4}\".format(pval))\n",
    "    print(\"We reject the null hypthoesis, so there is heterosecdasticity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ef916",
   "metadata": {},
   "source": [
    "# Checking for Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e880e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for autocorrelation\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# calculate the lag, optional\n",
    "lag = min(10, (len(X)//5))\n",
    "print('The number of lags will be {}'.format(lag))\n",
    "print('-'*100)\n",
    "\n",
    "# run the Ljung-Box test for no autocorrelation of residuals\n",
    "# test_results = diag.acorr_breusch_godfrey(est, nlags = lag, store = True)\n",
    "test_results = diag.acorr_ljungbox(est.resid, lags = lag)\n",
    "\n",
    "# grab the p-values and the test statistics\n",
    "ibvalue, p_val = test_results\n",
    "\n",
    "# print the results of the test\n",
    "if min(p_val) > 0.05:\n",
    "    print(\"The lowest p-value found was {:.4}\".format(min(p_val)))\n",
    "    print(\"We fail to reject the null hypthoesis, so there is no autocorrelation.\")\n",
    "    print('-'*100)\n",
    "else:\n",
    "    print(\"The lowest p-value found was {:.4}\".format(min(p_val)))\n",
    "    print(\"We reject the null hypthoesis, so there is autocorrelation.\")\n",
    "    print('-'*100)\n",
    "\n",
    "# plot autocorrelation\n",
    "sm.graphics.tsa.plot_acf(est.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f05524",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var = [\"Log Stock Price\"]\n",
    "x_vars = [\"Log Total Asset\",\n",
    "         \"Currency in Circulation/Total Asset\",\n",
    "         \"Effective Federal Funds Rate\",\n",
    "         \"Unemployment Rate\"]\n",
    "reg_vars = y_var + x_vars\n",
    "reg_data = data[reg_vars].dropna()\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046413d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datlib.plots import *\n",
    "corr_matrix_heatmap(reg_data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reg_data[y_var]\n",
    "X = reg_data[x_vars]\n",
    "X[\"Constant\"]=1\n",
    "results = sm.OLS(y,X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['Log Total Asset',\n",
    "         'Currency in Circulation/Total Asset',\n",
    "         'Effective Federal Funds Rate',\n",
    "         'Unemployment Rate',\n",
    "         'Log Stock Price']\n",
    "\n",
    "keys = keys\n",
    "reg_data = data_updated[keys].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a99d5",
   "metadata": {},
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "residuals = {}\n",
    "for y_var in reg_data.keys():\n",
    "    X_vars = list(reg_data.keys())\n",
    "    X_vars.remove(y_var)\n",
    "    X = reg_data[X_vars]\n",
    "    # Initial estimate should include constant\n",
    "    #   This won't be the case we regress the errors\n",
    "    X[\"Constant\"] = 1\n",
    "    # pass y_var as list for consistent structure\n",
    "    y = reg_data[[y_var]]\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    residuals[y_var] = results.resid\n",
    "residuals = pd.DataFrame(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c266a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.corr()[residuals.corr().abs() < 1].mul(-1).fillna(1).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7116a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcorr_pvalues = {}\n",
    "for y, Y in residuals.items():\n",
    "    pcorr_pvalues[y] = {}\n",
    "    for x, X in residuals.items():\n",
    "        if x != y:\n",
    "            pcorr_pvalues[y][x] = sm.OLS(Y,X).fit().pvalues[x]\n",
    "        \n",
    "        else:\n",
    "            pcorr_pvalues[y][x] = np.NaN\n",
    "pd.DataFrame(pcorr_pvalues).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin\n",
    "from pgmpy.estimators import PC\n",
    "c = PC(reg_data[keys].dropna())\n",
    "max_cond_vars = len(keys) - 2\n",
    "\n",
    "sig = 0.5\n",
    "model = c.estimate(return_type = \"dag\", variant = \"parallel\",\n",
    "                  significance_level = sig,\n",
    "                  max_cond_vars = max_cond_vars, ci_test = \"pearsonr\")\n",
    "\n",
    "edges = model.edges()\n",
    "pcorr = reg_data.pcorr()\n",
    "weights = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4654a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ArrowStyle\n",
    "\n",
    "def graph_DAG(edges, reg_data, title = \"\"):\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = [\"C0\" for g in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,12))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)#, k = 5/(len(sig_corr.keys())**.5))\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size = 1200,\n",
    "                     with_labels=True,  arrows=True,\n",
    "                     font_color = \"white\",\n",
    "                     font_size = 26, alpha = 1,\n",
    "                     width = 1, edge_color = \"C1\",\n",
    "                     arrowstyle=ArrowStyle(\"Fancy, head_length=3, head_width=1.5, tail_width=.1\"), ax = ax)\n",
    "\n",
    "graph_DAG(edges, reg_data, title = \"Directed Acyclic Graph\")\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a735d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datlib.plots import *\n",
    "corr_matrix_heatmap(data_updated.corr(), \n",
    "                    save_fig = False, \n",
    "                    pp = None, \n",
    "                    title = \"Correlation\")\n",
    "corr_matrix_heatmap(data_updated.pcorr(), save_fig = False, pp = None, title = \"Partial Correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0014a",
   "metadata": {},
   "source": [
    "## Using partial correlations to build a causal skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a898c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_graph = {key:[] for key in reg_data.keys()}\n",
    "for x in undirected_graph:\n",
    "    remaining_vars = [y for y in reg_data.keys() if y != x]\n",
    "    for y in remaining_vars:\n",
    "        undirected_graph[x].append(y)\n",
    "\n",
    "undirected_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec473e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import networkx as nx\n",
    "def graph_DAG(undirected_graph, reg_data, title = \"DAG Structure\"):\n",
    "    \n",
    "    # generate partial correlation matrix to draw values from\n",
    "    # for graph edges\n",
    "    pcorr_matrix = reg_data.pcorr()\n",
    "    graph = nx.Graph()\n",
    "    edges = []\n",
    "    edge_labels = {}\n",
    "    for edge in edges:\n",
    "                edge_labels[edge] = str(round(pcorr_matrix[edge[0]].loc[edge[1]],2))\n",
    "\n",
    "    # edge format: (\"i\", \"j\") --> from node i to node j\n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = [\"C0\" for g in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,12))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)#, k = 5/(len(sig_corr.keys())**.5))\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, \n",
    "                     node_size = 1000,\n",
    "                     with_labels=True,  arrows=True,\n",
    "                     arrowstyle = ArrowStyle(\"Fancy, head_length = 3, head_width = 1.5, tail_width = 1\"),\n",
    "                     font_size = 20, alpha = 1,\n",
    "                     width = 1, edge_color = \"C1\",\n",
    "                     font_color = \"black\",\n",
    "                     ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph,pos,\n",
    "                                 edge_labels=edge_labels,\n",
    "                                 font_color='green',\n",
    "                                 font_size=20)\n",
    "plt.close()\n",
    "graph_DAG(edges, reg_data)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = nx.DiGraph()\n",
    "g1.add_edges_from(reg_data(\"Log Stock Price\", \"Log Total Asset\"), (\"Log Stock Price\", \"Unemployment Rate\"), (\"Log Stock Price\", \"Effective Federal Funds Rate\"), (\"Log Stock Price\", \"Currency in Circulation/Total Asset\"))\n",
    "plt.tight_layout()\n",
    "nx.draw_networkx(g1, arrows=True)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb0ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec7d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317d771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "edges = reg_data(('Effective Federal Funds Rate', 'Log Stock Price'), ('Log Stock Price', 'Log Total Asset'), ('Log Stock Price', 'Unemployment Rate'), ('Log Stock Price', 'Currency in Circulation/Total Asset'))\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure()\n",
    "nx.draw(\n",
    "    G, pos, edge_color='black', width=1, linewidths=1,\n",
    "    node_size=500, node_color='pink', alpha=0.9,\n",
    "    labels={node: node for node in G.nodes()}\n",
    ")\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G, pos,\n",
    "    edge_labels={('Effective Federal Funds Rate', 'Log Stock Price'): 'AB', \n",
    "                 ('Log Stock Price', 'Log Total Asset'): 'BC', \n",
    "                 ('Log Stock Price', 'Unemployment Rate'): 'BD',\n",
    "                 ('Log Stock Price', 'Currency in Circulation/Total Asset'): 'BE'},\n",
    "    font_color='red'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e08c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "c = PC(reg_data)\n",
    "max_cond_vars = len(reg_data.keys()) - 2\n",
    "\n",
    "\n",
    "model = c.estimate(return_type = \"dag\",variant= \"parallel\",#\"orig\", \"stable\"\n",
    "                   significance_level = p_val, \n",
    "                   max_cond_vars = max_cond_vars, ci_test = \"pearsonr\")\n",
    "edges = model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b34926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0c313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55534848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c142f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
